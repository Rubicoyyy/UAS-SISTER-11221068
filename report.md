# Laporan Desain – Pub-Sub Log Aggregator

Nama : Syahrubi Alam Bahari  
NIM : 11221068  
Kelas : Sistem Paralel dan Terdistribusi B

Seluruh analisis berikut merujuk pada arsitektur terbaru yang terdiri dari empat layanan Docker Compose (aggregator, broker, storage, publisher) yang berjalan di jaringan internal tanpa akses publik. Sitasi mengacu pada buku utama (van Steen & Tanenbaum, 2023).

---

## T1 – Karakteristik Sistem Terdistribusi & Trade-off
Sistem ini memanfaatkan tiga karakter utama sistem terdistribusi: resource sharing, concurrency, dan scalability (van Steen & Tanenbaum, 2023). Resource sharing tercermin pada Redis dan Postgres yang dapat diakses bersamaan oleh beberapa worker aggregator. Concurrency muncul karena endpoint `POST /publish` tidak menunggu proses dedup; ia hanya memvalidasi dan memasukkan event ke antrean sehingga klien menerima respons 202 dengan latensi <15 ms pada uji lokal. Scalability dicapai melalui horizontal worker (`WORKER_COUNT`) dan fakta bahwa publisher dapat menjalankan beberapa replika tanpa memerlukan koordinasi eksplisit—selama mereka berbicara ke broker yang sama. Trade-off utamanya adalah memilih eventual consistency demi throughput. Setelah `publisher` mengirim 20.000 event dengan rasio duplikasi 35%, `GET /stats` menunjukkan 13.019 event unik setelah ±180 detik; selama window ini, `GET /events` belum tentu langsung menampilkan event terakhir, tetapi data akhir selalu konsisten karena constraint `(topic, event_id)` menjaga idempotensi. Konsistensi kuat dapat dicapai dengan transaksi serializable, tetapi biaya menulis ke Postgres meningkat 2x dalam eksperimen awal sehingga dipilih isolation READ COMMITTED yang lebih efisien.

## T2 – Alasan Memilih Publish-Subscribe
Arsitektur publish-subscribe dipilih karena pola kerja sistem menuntut loose coupling antara produser log dan konsumer yang melakukan dedup (van Steen & Tanenbaum, 2023). Bila pola client-server murni digunakan, setiap klien harus menunggu SQL insert selesai serta menangani retry sendiri. Dengan Pub-Sub, aggregator hanya berperan sebagai gateway HTTP yang seketika meletakkan payload ke antrean Redis, sedangkan worker terpisah melakukan transaksi database. Pendekatan ini juga memudahkan penambahan produser baru (misal agen log atau pipeline ETL) tanpa menaikkan kompleksitas aggregator; mereka cukup mengirim request HTTP sesuai skema. Selain itu Pub-Sub membuat sistem lebih tahan terhadap burst: saat load mendadak mencapai 2.500 event/detik, antrean Redis menyerap backlog tanpa membuat klien gagal. Broker menjadi buffer bersama yang dapat di-scale terpisah, sementara idempotent consumer memastikan tidak ada event ganda ketika aggregator atau worker mengalami restart.

## T3 – At-least-once vs Exactly-once & Peran Idempotent Consumer
Publisher sengaja mengimplementasikan mekanisme retry dengan rasio duplikasi 30–35% untuk meniru jaminan at-least-once (van Steen & Tanenbaum, 2023). Ketika aggregator menerima batch, ia langsung mengembalikan 202 sehingga klien tidak tahu apakah konsumer berhasil—ini definisi at-least-once. Exactly-once delivery memerlukan protokol koordinasi ekstra (mis. two-phase commit) yang akan menambah latensi. Sebaliknya, sistem ini mencapai efek exactly-once di sisi storage melalui idempotent consumer: worker menjalankan `INSERT ... ON CONFLICT DO NOTHING` dalam satu transaksi bersama update statistik. Jika SQL mengembalikan `rowcount=1`, berarti event unik; bila `rowcount=0`, worker menaikkan counter `duplicate_dropped` dan menulis log audit. Dengan pola ini, pengiriman ulang oleh publisher maupun oleh Redis setelah crash tidak akan menggandakan data. Tests `test_publish_batch_deduplicates` dan `test_concurrent_recording_is_idempotent` memverifikasi bahwa hanya satu insert yang berhasil meskipun ada 20 thread yang berlomba memasukkan event sama.

## T4 – Skema Penamaan Topic & Event_ID
Penamaan topic mengikuti pola hierarki sederhana `domain.subsystem` (contoh: `auth.login`), sedangkan `event_id` berupa UUID atau hash yang unik per topic. Kombinasi ini menghasilkan namespace komposit yang collision-resistant dan mudah diindeks sebagai primary key `(topic, event_id)` (van Steen & Tanenbaum, 2023). Topic dipakai sebagai dimensi logis untuk query `GET /events?topic=` sekaligus agregasi statistik; storing-nya di Postgres memudahkan pembuatan materialized view bila suatu saat diperlukan. Untuk menghindari kesalahan klien, endpoint `POST /publish` menerapkan validasi Pydantic: panjang string dibatasi 128 karakter, timestamp harus ISO8601, dan payload wajib berupa objek JSON. Jika ada batch besar, setiap elemen diberi indeks error sehingga klien tahu posisi event invalid. Strategi penamaan ini juga memudahkan dedup di level Redis; walaupun Redis hanya menyimpan JSON string, field `topic` dan `event_id` akan menjadi pengenal saat worker memproses event. Dengan demikian dedup dapat terjadi bahkan ketika ordering Redis tidak deterministik.

## T5 – Ordering Praktis & Dampaknya
Sistem tidak mengejar total ordering karena itu akan menurunkan throughput (van Steen & Tanenbaum, 2023). Ordering praktis yang digunakan adalah FIFO best-effort pada Redis list, digabung dengan timestamp ISO8601 serta monotonic counter internal `ingested_at`. Worker memproses event sesuai urutan BLPOP; namun ketika ada beberapa worker, urutan antar-topic bisa berubah. Hal ini dapat ditoleransi karena use case log aggregator hanya membutuhkan konsistensi per topic. Bila aplikasi downstream memerlukan ordering yang lebih kuat, mereka dapat menggunakan pasangan `(timestamp, ingested_at)` untuk melakukan sorting tambahan atau mengabaikan event yang tiba lebih lambat. Dampak utama dari strategi ini adalah eventual consistency: `GET /events` mungkin menampilkan event topic A sebelum topic B walaupun B dikirim lebih awal. Tetapi statistik tetap akurat karena setiap insert dilakukan dalam transaksi tunggal; begitu event masuk ke tabel `events`, ia tidak pernah bergerak lagi dan akan diurutkan berdasarkan kolom `ingested_at` saat query.

## T6 – Failure Modes & Mitigasi
Failure mode utama adalah crash pada aggregator, worker, Redis, atau Postgres. Untuk aggregator dan worker, FastAPI menjalankan lifecycle hook yang membatalkan task secara graceful sehingga tidak ada event yang diproses setengah jalan. Redis dikonfigurasi `appendonly yes`, artinya daftar event akan dipulihkan setelah container dibuat ulang. Postgres menggunakan volume `pg_data`; selama data directory tidak dihapus, constraint unik menjamin dedup tetap berlaku. Sementara itu publisher menerapkan retry otomatis (HTTP exception -> sleep 0.5 detik -> kirim ulang) sehingga kegagalan sementara (mis. queue penuh) menghasilkan at-least-once delivery. Dalam failure injection test, container `aggregator` dimatikan saat memproses batch ke-18. Setelah restart, worker kembali menarik event dari Redis, dan `duplicate_dropped` naik sesuai jumlah event yang sudah pernah tersimpan. Strategi ini sesuai rekomendasi toleransi kegagalan dengan retry + backoff serta storage durable (van Steen & Tanenbaum, 2023).

## T7 – Eventual Consistency & Peran Idempotency
Model konsistensi yang dipilih adalah eventual consistency dengan jaminan monotonic convergence per `(topic, event_id)` (van Steen & Tanenbaum, 2023). Selama publisher masih mengirim data, query pembaca mungkin melihat state lama karena worker memerlukan waktu untuk memproses antrean. Namun ketika traffic berhenti, semua event unik pasti berada di Postgres dan semua duplikat telah tercatat di statistik. Idempotency membuat convergence ini deterministik: event yang sama selalu menghasilkan state akhir yang identik meskipun diterima berkali-kali. Untuk memudahkan audit, log aggregator menandai setiap event dengan status `processed` atau `duplicate`, sehingga operator dapat menelusuri apakah ada topic yang sering mengirim ulang. Endpoint `GET /stats` juga mengembalikan daftar topic dan total event unik, sehingga konsumen bisa melakukan verifikasi akhir apakah seluruh partisi sinkron. Dengan cara ini, eventual consistency tetap memberikan visibilitas cukup tanpa memerlukan locking global atau ordering ketat.

## T8 – Desain Transaksi & Isolation Level
Setiap worker menjalankan transaksi ACID singkat: `BEGIN; INSERT ... ON CONFLICT DO NOTHING; UPDATE system_metrics ...; COMMIT;`. Postgres bekerja pada isolation READ COMMITTED untuk menghindari pembacaan phantom yang tidak relevan sekaligus menjaga throughput (van Steen & Tanenbaum, 2023). Lost update dicegah melalui constraint unik dan operasi `UPDATE ... SET column = column + 1` yang atomik. Jika dua worker menulis event sama, hanya salah satu yang berhasil karena Postgres mendeteksi konflik pada primary key; worker lain melihat `rowcount=0` dan menganggapnya duplikat. Transaksi juga mencakup pembaruan statistik, sehingga tidak ada keadaan di mana event berhasil tetapi counter tidak naik. Saat endpoint `POST /publish` menerima batch besar, seluruh batch tidak dibungkus transaksi; sebaliknya tiap event diproses sendiri-sendiri agar kegagalan satu item tidak menggagalkan lainnya. Kebijakan ini kompatibel dengan idempotency karena event yang gagal validasi cukup diminta ulang lalu akan memicu insert baru tanpa mengganggu item sebelumnya.

## T9 – Kontrol Konkurensi & Pola Idempotent Write
Kontrol konkurensi mengandalkan kombinasi unique constraint, retry driver bawaan Postgres, dan worker paralel. Karena hanya satu index `(topic, event_id)`, konflik tulis terjadi pada tingkat row-level lock sehingga worker lain cukup menunggu giliran tanpa deadlock. Selain itu aggregator memiliki fallback queue in-memory dengan batas `QUEUE_MAXSIZE`; jika penuh, API mengembalikan 503 untuk memaksa publisher melakukan retry dengan backoff. Ini adalah bentuk admission control untuk mencegah kontensi lebih jauh (van Steen & Tanenbaum, 2023). Pada sisi aplikasi, pola idempotent write dilakukan dengan cara mengubah event menjadi bentuk deterministik (payload JSON canonical) sebelum dimasukkan ke queue. Tests `test_concurrent_recording_is_idempotent` menjalankan 20 thread yang memasukkan event sama; hasilnya tepat satu insert sukses, sedangkan 19 lainnya meningkatkan `duplicate_dropped`. Ini membuktikan bahwa walaupun worker berjalan bersamaan, konflik dapat diselesaikan tanpa race-condition, dan sistem tetap konsisten.

## T10 – Orkestrasi, Keamanan Jaringan, Persistensi, Observability
Docker Compose mengorkestrasi empat layanan pada satu jaringan bridge internal tanpa port yang terekspos keluar selain `aggregator:8080`. Postgres dan Redis tidak membuka port host sehingga sesuai prinsip keamanan lokal (van Steen & Tanenbaum, 2023). Persistensi dijaga melalui volume `pg_data` dan `redis_data`; demonstrasi video menunjukkan bahwa setelah `docker compose down` diikuti `docker compose up`, `GET /events` tetap memuat data yang sama dan duplikasi baru tetap dicegah. Observability diwujudkan oleh endpoint `GET /stats`, `GET /healthz`, serta log structured yang menyebut `worker_id`, topic, dan event_id. Compose juga menambahkan health check untuk Postgres (`pg_isready`) dan Redis (`redis-cli ping`) sebelum aggregator menerima traffic. Untuk uji otomatis, `python -m pytest` menjalankan 12 tes yang mencakup validasi skema, integrasi API, serta pengujian stress kecil. Instruksi build/run, asumsi arsitektur, serta tautan video demo terdokumentasi di README.md agar reviewer dapat memverifikasi seluruh rubrik hanya dengan mengikuti langkah yang sama.

---

## Referensi
van Steen, M., & Tanenbaum, A. S. (2023). *Distributed Systems*. Maarten van Steen.
